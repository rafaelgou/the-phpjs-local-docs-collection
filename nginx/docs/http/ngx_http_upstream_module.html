<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Module ngx_http_upstream_module</title><style type="text/css">body { font-family: Georgia, serif; } p { text-align: justify; } table.news p { margin-top: 0; } table.news td { vertical-align: baseline; } table.news .date { text-align: right; padding-right: 0.5em; white-space: nowrap; } table.donors td { vertical-align: baseline; } table.donors li { text-align: left; } div.directive { background: #EEEEEE; padding: 10pt 10pt 10pt 0; } div.directive td { vertical-align: baseline; } div.directive pre { padding: 0; margin: 0; } div.directive p { margin: 5pt 0 0 0; font-size: 80%; } div#banner { background: #EEEEEE; padding: 10pt 10pt 10pt 0; } a.notrans { color: gray; text-decoration:none; } span.initial { font-size: 200%; float: left; padding-right: 10pt;} li { text-align: justify; padding-top: 0.5em; } .compact li { padding-top: 0; } dt { padding-top: 0.5em; } .compact dt { padding-top: 0; } dd { text-align: justify; } td.list { background: #EEEEEE; } blockquote.note { text-align: justify; background: #EEEEEE; border: none; margin: 1em; padding: 0.5em; } blockquote.example { background: transparent; border: none; margin: 1em; padding: 0.5em; } blockquote.example pre { padding: 0; margin: 0; } sup { font-size: 50%; }</style><script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-27974099-2']);
        _gaq.push(['_setDomainName', 'nginx.org']);
        _gaq.push(['_trackPageview']);

        (function() {
           var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
           ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
           var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();

    </script></head><body><table width="100%"><tr><td width="70%"><div id="banner"><center><table><tr><td align="center"><a href="http://nginx.com/products/"><strong>Make your web site fast and reliable.</strong></a></td></tr><tr><td align="center"><i>NGINX Plus for mission critical environments.</i></td></tr></table></center></div></td><td align="right"><a href="../../../index.html"><img src="../../nginx.gif" alt="nginx" border="0"></a></td></tr><tr><td width="70%"><center><h3>Module ngx_http_upstream_module</h3></center></td><td rowspan="2" align="right" valign="top"><br>english<br><a href="../../../ru/docs/http/ngx_http_upstream_module.html">русский</a><br><br><a href="../../../cn/docs/http/ngx_http_upstream_module.html">简体中文</a><br><a class="notrans">עברית</a><br><a class="notrans">日本語</a><br><a class="notrans">türkçe</a><br><br><a href="../../../index.html">news</a><br><a href="../../index.html">about</a><br><a href="../../download.html">download</a><br><a href="../../security_advisories.html">security advisories</a><br><a href="../introduction.html">documentation</a><br><a href="../../pgp_keys.html">pgp keys</a><br><a href="../faq.html">faq</a><br><a href="../../links.html">links</a><br><a href="../../books.html">books</a><br><a href="../../support.html">support</a><br><a href="../../donation.html">donation</a><br><br><a href="http://trac.nginx.org/nginx">trac</a><br><a href="http://wiki.nginx.org/">wiki</a><br><a href="http://twitter.com/nginxorg">twitter</a><br><a href="http://nginx.com/">nginx.com</a><br></td></tr><tr><td valign="top"><table width="100%"><tr><td align="left"><a href="ngx_http_upstream_module.html#example">Example Configuration</a><br><a href="ngx_http_upstream_module.html#directives">Directives</a><br>     <a href="ngx_http_upstream_module.html#upstream">upstream</a><br>     <a href="ngx_http_upstream_module.html#server">server</a><br>     <a href="ngx_http_upstream_module.html#zone">zone</a><br>     <a href="ngx_http_upstream_module.html#ip_hash">ip_hash</a><br>     <a href="ngx_http_upstream_module.html#keepalive">keepalive</a><br>     <a href="ngx_http_upstream_module.html#least_conn">least_conn</a><br>     <a href="ngx_http_upstream_module.html#health_check">health_check</a><br>     <a href="ngx_http_upstream_module.html#match">match</a><br>     <a href="ngx_http_upstream_module.html#sticky">sticky</a><br>     <a href="ngx_http_upstream_module.html#sticky_cookie_insert">sticky_cookie_insert</a><br>     <a href="ngx_http_upstream_module.html#upstream_conf">upstream_conf</a><br><a href="ngx_http_upstream_module.html#variables">Embedded Variables</a><br></td></tr></table>

<a name="summary"></a><p>
The <code>ngx_http_upstream_module</code> module
is used to define groups of servers that can be referenced
by the <a href="ngx_http_proxy_module.html#proxy_pass">proxy_pass</a>,
<a href="ngx_http_fastcgi_module.html#fastcgi_pass">fastcgi_pass</a>, and
<a href="ngx_http_memcached_module.html#memcached_pass">memcached_pass</a> directives.
</p>


<a name="example"></a><center><h4>Example Configuration</h4></center><p>
</p> <blockquote class="example"><pre>
upstream <strong>backend</strong> {
    server backend1.example.com       weight=5;
    server backend2.example.com:8080;
    server unix:/tmp/backend3;

    server backup1.example.com:8080   backup;
    server backup2.example.com:8080   backup;
}

server {
    location / {
        proxy_pass http://<strong>backend</strong>;
    }
}
</pre></blockquote><p> 
</p><p>
Dynamically configurable group,
available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only:
</p> <blockquote class="example"><pre>
upstream <strong>appservers</strong> {
    zone appservers 64k;

    server appserv1.example.com      weight=5;
    server appserv2.example.com:8080 fail_timeout=5s slow_start=30s;
    server 192.0.2.1                 max_fails=3;

    server reserve1.example.com:8080 backup;
    server reserve2.example.com:8080 backup;
}

server {
    location / {
        proxy_pass http://<strong>appservers</strong>;
        health_check;
    }

    location /upstream_conf {
        upstream_conf;
        allow 127.0.0.1;
        deny all;
    }
}
</pre></blockquote><p> 
</p>


<a name="directives"></a><center><h4>Directives</h4></center><a name="upstream"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>upstream</strong> <code><i>name</i></code> { ... }</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>http</code><br>
                </td>
                </tr>
            </table></div><p>
Defines a group of servers.
Servers can listen on different ports.
In addition, servers listening on TCP and UNIX-domain sockets
can be mixed.
</p><p>
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com weight=5;
    server 127.0.0.1:8080       max_fails=3 fail_timeout=30s;
    server unix:/tmp/backend3;
}
</pre></blockquote><p> 
</p><p>
By default, requests are distributed between the servers using a
weighted round-robin balancing method.
In the above example, each 7 requests will be distributed as follows:
5 requests go to <code>backend1.example.com</code>
and one request to each of the second and third servers.
If an error occurs during communication with a server, the request will
be passed to the next server, and so on until all of the functioning
servers will be tried.
If a successful response could not be obtained from any of the servers,
the client will receive the result of the communication with the last server.
</p><a name="server"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>server</strong> <code><i>address</i></code> [<code><i>parameters</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Defines the <code><i>address</i></code> and other <code><i>parameters</i></code>
of a server.
The address can be specified as a domain name or IP address,
with an optional port, or as a UNIX-domain socket path
specified after the “<code>unix:</code>” prefix.
If a port is not specified, the port 80 is used.
A domain name that resolves to several IP addresses defines
multiple servers at once.
</p><p>
The following parameters can be defined:
</p> <dl class="compact">

<dt><code>weight</code>=<code><i>number</i></code></dt>
<dd>
sets the weight of the server, by default, 1.
</dd>

<dt><code>max_fails</code>=<code><i>number</i></code></dt>
<dd>
sets the number of unsuccessful attempts to communicate with the server
that should happen in the duration set by the <code>fail_timeout</code>
parameter to consider the server unavailable for a duration also set by the
<code>fail_timeout</code> parameter.
By default, the number of unsuccessful attempts is set to 1.
The zero value disables the accounting of attempts.
What is considered an unsuccessful attempt is defined by the
<a href="ngx_http_proxy_module.html#proxy_next_upstream">proxy_next_upstream</a>,
<a href="ngx_http_fastcgi_module.html#fastcgi_next_upstream">fastcgi_next_upstream</a>, and
<a href="ngx_http_memcached_module.html#memcached_next_upstream">memcached_next_upstream</a>
directives.
</dd>

<dt><code>fail_timeout</code>=<code><i>time</i></code></dt>
<dd>
sets
<ul class="compact">

<li>
the time during which the specified number of unsuccessful attempts to
communicate with the server should happen to consider the server unavailable;
</li>

<li>
and the period of time the server will be considered unavailable.
</li>

</ul>
By default, the parameter is set to 10 seconds.
</dd>

<dt><code>slow_start</code>=<code><i>time</i></code></dt>
<dd>
sets the <code><i>time</i></code> during which the server will recover its weight
from zero to a nominal value, when unhealthy server becomes
<a href="ngx_http_upstream_module.html#health_check">healthy</a>,
or when the server becomes available after a period of time
it was considered unavailable.
Default value is zero, i.e. slow start is disabled.
<blockquote class="note">
This functionality is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote>
</dd>

<dt><code>backup</code></dt>
<dd>
marks the server as a backup server.
It will be passed requests when the primary servers are unavailable.
</dd>

<dt><code>down</code></dt>
<dd>
marks the server as permanently unavailable; used along with
the <a href="ngx_http_upstream_module.html#ip_hash">ip_hash</a> directive.
</dd>

<dt><code>route</code>=<code><i>string</i></code></dt>
<dd>
sets the server route name.
<blockquote class="note">
This functionality is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote>
</dd>

</dl><p> 
</p><p>
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com     weight=5;
    server 127.0.0.1:8080           max_fails=3 fail_timeout=30s;
    server unix:/tmp/backend3;

    server backup1.example.com:8080 backup;
}
</pre></blockquote><p> 

</p> <blockquote class="note">
If there is only a single server in a group, <code>max_fails</code>,
<code>fail_timeout</code> and <code>slow_start</code> parameters
are ignored, and such a server will never be considered unavailable.
</blockquote><p> 
</p><a name="zone"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>zone</strong> <code><i>name</i></code> <code><i>size</i></code>;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Makes the group dynamically configurable.
Defines the <code><i>name</i></code> and <code><i>size</i></code> of a shared
memory zone that keeps group’s configuration and run-time state that are
shared between worker processes.
Such groups allow to add, remove, and modify servers at run time.
The configuration is accessible via a special location handled by
<a href="ngx_http_upstream_module.html#upstream_conf">upstream_conf</a>.
</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p><a name="ip_hash"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>ip_hash</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Specifies that a group should use a load balancing method where requests
are distributed between servers based on client IP addresses.
The first three octets of the client IPv4 address, or the entire IPv6 address,
are used as a hashing key.
The method ensures that requests from the same client will always be
passed to the same server except when this server is unavailable.
In the latter case client requests will be passed to another server.
Most probably, it will always be the same server as well.
</p> <blockquote class="note">
IPv6 addresses are supported starting from versions 1.3.2 and 1.2.2.
</blockquote><p> 
</p><p>
If one of the servers needs to be temporarily removed, it should
be marked with the <code>down</code> parameter in
order to preserve the current hashing of client IP addresses.
</p><p>
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    ip_hash;

    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com <strong>down</strong>;
    server backend4.example.com;
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
Until versions 1.3.1 and 1.2.2, it was not possible to specify a weight for
servers using the <code>ip_hash</code> load balancing method.
</blockquote><p> 
</p><a name="keepalive"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>keepalive</strong> <code><i>connections</i></code>;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.1.4.

            </p></div><p>
Activates the cache for connections to upstream servers.
</p><p>
The <code><i>connections</i></code> parameter sets the maximum number of
idle keepalive connections to upstream servers that are preserved in
the cache of each worker process.
When this number is exceeded, the least recently used connections
are closed.
</p> <blockquote class="note">
It should be particularly noted that the <code>keepalive</code> directive
does not limit the total number of connections to upstream servers
that an nginx worker process can open.
The <code><i>connections</i></code> parameter should be set to a number small enough
to let upstream servers process new incoming connections as well.
</blockquote><p> 
</p><p>
Example configuration of memcached upstream with keepalive connections:
</p> <blockquote class="example"><pre>
upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;

    keepalive 32;
}

server {
    ...

    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }

}
</pre></blockquote><p> 
</p><p>
For HTTP, the <a href="ngx_http_proxy_module.html#proxy_http_version">proxy_http_version</a>
directive should be set to “<code>1.1</code>”
and the “Connection” header field should be cleared:
</p> <blockquote class="example"><pre>
upstream http_backend {
    server 127.0.0.1:8080;

    keepalive 16;
}

server {
    ...

    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        ...
    }
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
Alternatively, HTTP/1.0 persistent connections can be used by passing the
“Connection: Keep-Alive” header field to an upstream server,
though this method is not recommended.
</blockquote><p> 
</p><p>
For FastCGI servers, it is required to set
<a href="ngx_http_fastcgi_module.html#fastcgi_keep_conn">fastcgi_keep_conn</a>
for keepalive connections to work:
</p> <blockquote class="example"><pre>
upstream fastcgi_backend {
    server 127.0.0.1:9000;

    keepalive 8;
}

server {
    ...

    location /fastcgi/ {
        fastcgi_pass fastcgi_backend;
        fastcgi_keep_conn on;
        ...
    }
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
When using load balancer methods other than the default
round-robin method, it is necessary to activate them before
the <code>keepalive</code> directive.
</blockquote><p> 

</p> <blockquote class="note">
SCGI and uwsgi protocols do not have a notion of keepalive connections.
</blockquote><p> 
</p><a name="least_conn"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>least_conn</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table>
                        <p>
                    This directive appeared in versions 1.3.1 and 1.2.2.
                  
                        </p>
                    </div><p>
Specifies that a group should use a load balancing method where a request
is passed to the server with the least number of active connections,
taking into account weights of servers.
If there are several such servers, they are tried using a
weighted round-robin balancing method.
</p><a name="health_check"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>health_check</strong> 
    [<code>interval=</code><code><i>time</i></code>]

    [<code>fails=</code><code><i>number</i></code>]
    [<code>passes=</code><code><i>number</i></code>]
    [<code>uri=</code><code><i>uri</i></code>]
    [<code>match=</code><code><i>name</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>location</code><br>
                </td>
                </tr>
            </table></div><p>
Enables periodic health checks of the servers in a
<a href="ngx_http_upstream_module.html#upstream">group</a> referenced in the surrounding location.
</p><p>
The following optional parameters are supported:
</p> <ul class="compact">

<li>
<code>interval</code>
sets the interval between two consecutive health checks,
by default, 5 seconds;
</li>

<li>
<code>fails</code>
sets the number of consecutive failed health checks of a particular server
after which this server will be considered unhealthy,
by default, 1;
</li>

<li>
<code>passes</code>
sets the number of consecutive passed health checks of a particular server
after which the server will be considered healthy,
by default, 1;
</li>

<li>
<code>uri</code>
defines the URI used in health check requests,
by default, “<code>/</code>”;
</li>

<li>
<code>match</code>
specifies the <code>match</code> block configuring the tests that a
response should pass in order for a health check to pass;
by default, the response should have status code 2xx or 3xx.
</li>

</ul><p> 
</p><p>
For example,
</p> <blockquote class="example"><pre>
location / {
    proxy_pass http://backend;
    health_check;
}
</pre></blockquote><p> 
will send “<code>/</code>” requests to each
server in the <code>backend</code> group every five seconds.
If any communication error or timeout occurs, or a
proxied server responds with the status code other than
2xx or 3xx, the health check will fail, and the server will
be considered unhealthy.
Client requests are not passed to unhealthy servers.
</p><p>
Health checks can be configured to test the status code of a response,
presence of certain header fields and their values,
and the body contents.
Tests are configured separately using the <a href="ngx_http_upstream_module.html#match">match</a> directive
and referenced in the <code>match</code> parameter.
For example:
</p> <blockquote class="example"><pre>
http {
    server {
    ...
        location / {
            proxy_pass http://backend;
            health_check match=welcome;
        }
    }

    match welcome {
        status 200;
        header Content-Type = text/html;
        body ~ "Welcome to nginx!";
    }
}
</pre></blockquote><p> 
This configuration tells that for a health check to pass, the response to a
health check request should succeed,
have status 200, content type “<code>text/html</code>”,
and contain “<code>Welcome to nginx!</code>” in the body.
</p><p>
The server group must reside in the <a href="ngx_http_upstream_module.html#zone">shared memory</a>.
</p><p>
If several health checks are defined for the same group of servers,
a single failure of any check will make the corresponding server be
considered unhealthy.
</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p><a name="match"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>match</strong> <code><i>name</i></code> { ... }</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>http</code><br>
                </td>
                </tr>
            </table></div><p>
Defines the named test set used to verify responses to health check requests.
</p><p>
The following items can be tested in a response:
</p> <dl class="compact">

<dt><code>status 200;</code></dt>
<dd>status is 200</dd>

<dt><code>status ! 500;</code></dt>
<dd>status is not 500</dd>

<dt><code>status 200 204;</code></dt>
<dd>status is 200 or 204</dd>

<dt><code>status ! 301 302;</code></dt>
<dd>status is neither 301 nor 302</dd>

<dt><code>status 200-399;</code></dt>
<dd>status is in the range from 200 to 399</dd>

<dt><code>status ! 400-599;</code></dt>
<dd>status is not in the range from 400 to 599</dd>

<dt><code>status 301-303 307;</code></dt>
<dd>status is either 301, 302, 303, or 307</dd>

</dl><p> 

</p> <dl class="compact">

<dt><code>header Content-Type = text/html;</code></dt>
<dd>
header contains “Content-Type”
with value <code>text/html</code>
</dd>

<dt><code>header Content-Type != text/html;</code></dt>
<dd>
header contains “Content-Type”
with value other than <code>text/html</code>
</dd>

<dt><code>header Connection ~ close;</code></dt>
<dd>
header contains “Connection”
with value matching regular expression <code>close</code>
</dd>

<dt><code>header Connection !~ close;</code></dt>
<dd>
header contains “Connection”
with value not matching regular expression <code>close</code>
</dd>

<dt><code>header Host;</code></dt>
<dd>header contains “Host”</dd>

<dt><code>header ! X-Accel-Redirect;</code></dt>
<dd>header lacks “X-Accel-Redirect”</dd>

</dl><p> 

</p> <dl class="compact">

<dt><code>body ~ "Welcome to nginx!";</code></dt>
<dd>
body matches regular expression “<code>Welcome to nginx!</code>”
</dd>

<dt><code>body !~ "Welcome to nginx!";</code></dt>
<dd>
body does not match regular expression “<code>Welcome to nginx!</code>”
</dd>

</dl><p> 
</p><p>
If several tests are specified,
the response matches only if it matches all tests.
</p> <blockquote class="note">
Only the first 256k of the response body are examined.
</blockquote><p> 
</p><p>
Examples:
</p> <blockquote class="example"><pre>
# status is 200, content type is "text/html",
# and body contains "Welcome to nginx!"
match welcome {
    status 200;
    header Content-Type = text/html;
    body ~ "Welcome to nginx!";
}
</pre></blockquote><p> 

</p> <blockquote class="example"><pre>
# status is not one of 301, 302, 303, or 307, and header does not have "Refresh:"
match not_redirect {
    status ! 301-303 307;
    header ! Refresh;
}
</pre></blockquote><p> 

</p> <blockquote class="example"><pre>
# status ok and not in maintenance mode
match server_ok {
    status 200-399;
    body !~ "maintenance mode";
}
</pre></blockquote><p> 

</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p><a name="sticky"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>sticky</strong> <code>route</code> <code><i>variable</i></code> ...;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Enables session affinity, which causes requests that contain route to the
server to be passed to this server in a group of servers.
Example:
</p> <blockquote class="example"><pre>
map $cookie_JSESSIONID $route_cookie {
    ~.+\.(?P&lt;route&gt;\w+)$ $route;
}

map $request_uri $route_uri {
    ~jsessionid=.+\.(?P&lt;route&gt;\w+)$ $route;
}

upstream backend {
    server backend1.example.com route=a;
    server backend2.example.com route=b;

    sticky route $route_cookie $route_uri;
}
</pre></blockquote><p> 
Here, the “<code>JSESSIONID</code>” cookie is inspected for a server
route first, and if not found, the route from the URI is used.
</p><p>
A request that does not contain a server route is passed to the server
selected by the configured balancing method.
If a request cannot be processed by the designated server, the new server
is selected as if the client has not been bound yet.
</p><p>
The directive specifies variables that are examined for the route.
This route is compared with routes specified in the <a href="ngx_http_upstream_module.html#server">server</a>
directives.
The first non-empty variable is used for server search.
</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p><a name="sticky_cookie_insert"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>sticky_cookie_insert</strong> <code><i>name</i></code>
[<code>expires=</code><code><i>time</i></code>]
[<code>domain=</code><code><i>host</i></code>]
[<code>path=</code><code><i>path</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Enables session affinity, which causes requests from the same client to be
passed to the same server in a group of servers.
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com;
    server backend2.example.com;

    sticky_cookie_insert srv_id expires=1h domain=example.com path=/;
}
</pre></blockquote><p> 
</p><p>
A request that comes from a client not yet bound to a particular server
is passed to the server selected by the configured balancing method.
Further requests from the same client are passed to the same server.
If a request cannot be processed by the designated server, the new server
is selected as if the client has not been bound yet.
</p><p>
Information about the bound server is kept in an HTTP cookie.
The first parameter sets the name of the cookie to be inserted or inspected.
Additional parameters may be as follows:
</p> <dl class="compact">

<dt><code>expires</code></dt>
<dd>
Sets the time for which a browser should keep the cookie.
The parameter <code>max</code> will cause the cookie to expire on
“<code>31 Dec 2037 23:55:55 GMT</code>”.
This is the maximum time understood by old browsers.
If the parameter is not specified, it will cause the cookie to expire at
the end of a browser session.
</dd>

<dt><code>domain</code></dt>
<dd>
Defines the domain for which the cookie is set.
</dd>

<dt><code>path</code></dt>
<dd>
Defines the path for which the cookie is set.
</dd>

</dl><p> 
If any parameters are omitted, the corresponding cookie fields are not set.
</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p><a name="upstream_conf"></a><div class="directive"><table cellspacing="0">
                <tr>
                <td>
            syntax:
                </td>
                <td>
            <code><strong>upstream_conf</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <td>
            default:
                </td>
                <td>
            
            —
                </td>
                </tr>
            
                <tr>
                <td>
            context:
                </td>
                <td>
            <code>location</code><br>
                </td>
                </tr>
            </table></div><p>
Turns on the HTTP interface of upstream configuration in the surrounding
location.
Access to this location should be
<a href="ngx_http_core_module.html#satisfy">limited</a>.
</p><p>
Configuration commands can be used to:
</p> <ul class="compact">

<li>view all primary or backup servers in a group;</li>

<li>view an individual server;</li>

<li>modify an individual server;</li>

<li>add a new server (see the note below);</li>

<li>remove an individual server.</li>

</ul><p> 
</p> <blockquote class="note">
As noted in the <a href="ngx_http_upstream_module.html#server">server</a> directive, specifying a server
as a domain name may result in several servers being added to the group.
Since addresses in a group are not required to be unique, individual
servers in a group can be uniquely referenced to only by their ID.
IDs are assigned automatically and shown on viewing of the group configuration.
</blockquote><p> 
</p><p>
A configuration command consists of parameters passed as request arguments,
for example:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers
</pre></blockquote><p> 
</p><p>
The following parameters are supported:

</p> <dl>

<dt>
<code>upstream=</code><code><i>name</i></code></dt>
<dd>
Selects a group.
This parameter is mandatory.
</dd>

<dt>
<code>backup=</code>
</dt>
<dd>
If not set, selects primary servers in the group.
If set, selects backup servers in the group.
</dd>

<dt>
<code>id=</code><code><i>number</i></code></dt>
<dd>
Selects an individual primary or backup server in the group.
</dd>

<dt>
<code>remove=</code></dt>
<dd>
Removes an individual primary or backup server from the group.
</dd>

<dt>
<code>add=</code></dt>
<dd>
Adds a new primary or backup server to the group.
</dd>

<dt>
<code>server=</code><code><i>address</i></code></dt>
<dd>
Same as the “<code>address</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>weight=</code><code><i>number</i></code></dt>
<dd>
Same as the “<code>weight</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>max_fails=</code><code><i>number</i></code></dt>
<dd>
Same as the “<code>max_fails</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>fail_timeout=</code><code><i>time</i></code></dt>
<dd>
Same as the “<code>fail_timeout</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>slow_start=</code><code><i>time</i></code></dt>
<dd>
Same as the “<code>slow_start</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>down=</code></dt>
<dd>
Same as the “<code>down</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>up=</code></dt>
<dd>
The opposite of the “<code>down</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

<dt>
<code>route=</code><code><i>string</i></code></dt>
<dd>
Same as the “<code>route</code>” parameter
of the <a href="ngx_http_upstream_module.html#server">server</a> directive.
</dd>

</dl><p> 

The first three parameters select a target the command applies to.
Without other parameters, the command shows configuration of the selected
target.
</p><p>
For example, to view the primary servers in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers
</pre></blockquote><p> 

To view the backup servers in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;backup=
</pre></blockquote><p> 

To view an individual primary server in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;id=42
</pre></blockquote><p> 

To view an individual backup server in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;backup=&amp;id=42
</pre></blockquote><p> 
</p><p>
To add a new primary or backup server to the group,
specify its address in the “<code>server=</code>” parameter.
Without other parameters specified, a server will be added with other
parameters set to their default values (see the <a href="ngx_http_upstream_module.html#server">server</a> directive).
</p><p>
For example, to add a new primary server to the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?add=&amp;upstream=appservers&amp;server=127.0.0.1:8080
</pre></blockquote><p> 

To add a new backup server to the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?add=&amp;upstream=appservers&amp;backup=&amp;server=127.0.0.1:8080
</pre></blockquote><p> 

To add a new primary server to the group,
set its parameters to non-default values
and mark it as “<code>down</code>”, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?add=&amp;upstream=appservers&amp;server=127.0.0.1:8080&amp;weight=2&amp;max_fails=3&amp;fail_timeout=3s&amp;down=
</pre></blockquote><p> 
</p><p>
To remove an individual primary or backup server from the group,
select it with the <code>id=</code> parameter.
</p><p>
For example, to remove an individual primary server from the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?remove=&amp;upstream=appservers&amp;id=42
</pre></blockquote><p> 

To remove an individual backup server from the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?remove=&amp;upstream=appservers&amp;backup=&amp;id=42
</pre></blockquote><p> 
</p><p>
To modify an individual primary or backup server in the group,
select it with the <code>id=</code> parameter.
</p><p>
For example, to modify an individual primary server in the group
by marking it as “<code>down</code>”, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;id=42&amp;down=
</pre></blockquote><p> 

To modify the address of an individual backup server in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;backup=&amp;id=42&amp;server=192.0.2.3:8123
</pre></blockquote><p> 

To modify other parameters of an individual primary server in the group, send:
</p> <blockquote class="example"><pre>
http://127.0.0.1/upstream_conf?upstream=appservers&amp;id=42&amp;max_fails=3&amp;weight=4
</pre></blockquote><p> 

</p><p>
</p> <blockquote class="note">
This directive is available as part of our <a href="http://nginx.com/products/">commercial subscription</a> only.
</blockquote><p> 
</p>


<a name="variables"></a><center><h4>Embedded Variables</h4></center><p>
The <code>ngx_http_upstream_module</code> module
supports the following embedded variables:
</p> <dl class="compact">

<dt><code>$upstream_addr</code></dt>
<dd>
keeps the IP address and port of the server,
or the path to the UNIX-domain socket.
If several servers were contacted during request processing,
their addresses are separated by commas, e.g.
“<code>192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock</code>”.
If an internal redirect from one server group to another happens,
initiated by
“X-Accel-Redirect” or
<a href="ngx_http_core_module.html#error_page">error_page</a>,
then the server addresses from different groups are separated by colons, e.g.
“<code>192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock : 192.168.10.1:80, 192.168.10.2:80</code>”.
</dd>

<dt><code>$upstream_cache_status</code></dt>
<dd>
keeps the status of accessing a response cache (0.8.3).
The status can be either “<code>MISS</code>”, 
“<code>BYPASS</code>”, “<code>EXPIRED</code>”,
“<code>STALE</code>”, “<code>UPDATING</code>” or
“<code>HIT</code>”.
</dd>

<dt><code>$upstream_response_length</code></dt>
<dd>
keeps the lengths of responses obtained from the upstream servers (0.7.27);
lengths are kept in bytes.
Several response lengths are separated by commas and colons
like addresses in the <code>$upstream_addr</code> variable.
</dd>

<dt><code>$upstream_response_time</code></dt>
<dd>
keeps times of responses obtained from upstream servers;
times are kept in seconds with a milliseconds resolution.
Several response times are separated by commas and colons
like addresses in the <code>$upstream_addr</code> variable.
</dd>

<dt><code>$upstream_status</code></dt>
<dd>
keeps codes of responses obtained from upstream servers.
Several response codes are separated by commas and colons
like addresses in the <code>$upstream_addr</code> variable.
</dd>

<dt><code>$upstream_http_...</code></dt>
<dd>
keep server response header fields.
For example, the “Server” response header field
is available through the <code>$upstream_http_server</code> variable.
The rules of converting header field names to variable names are the same
as for the variables that start with the
“<a href="ngx_http_core_module.html#variables">$http_</a>” prefix.
Only the last server’s response header fields are saved.
</dd>

</dl><p> 
</p>

</td></tr></table></body></html>
